---
title: "Lab 12: MATH 4753"
author: "Justin Kleiber"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: yes
    toc_float: yes
    theme: spacelab
    highlight: pygments
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Task 1

First, the working directory is confirmed

```{r}
getwd()
```

# Task 2

First a sample called x1 is used to verify several hypotheses using the T test in R:

```{r}
set.seed(55);
x1=rnorm(30,mean=25,sd=5)
```

Then for the hypotheses, the following test results are generated:   

$H_0: \mu = 22$:
```{r}
val = t.test(x1, mu=22)
val$p.value
val$conf.int
```

In this instance, the p-value of the test is quite less than 0.05, meaning the null hypothesis can be rejected as implausible. The confidence interval verifies this by showing the lower bound to be higher than 22.


$H_0: \mu = 23$:
```{r}
val = t.test(x1, mu=23)
val$p.value
val$conf.int
```

The p-value for $\mu = 23$ is much greater than for 22, but can still be rejected as implausible due to being less than 0.05. 23 is pretty close to the lower bound of the confidence interval though, so it is definitely more likely than an estimate of 22.

$H_0: \mu = 24$:
```{r}
val = t.test(x1, mu=24)
val$p.value
val$conf.int
```

The null hypothesis value of 24 falls in the confidence interval and has a p value greater than 0.05. Thus, the null hypothesis is plausible.

$H_0: \mu = 25$:
```{r}
val = t.test(x1, mu=25)
val$p.value
val$conf.int
```

The null hypothesis value of 25 falls in the confidence interval and has a p value significantly greater than 0.05. Thus, the null hypothesis is plausible.

$H_0: \mu = 26$:
```{r}
val = t.test(x1, mu=26)
val$p.value
val$conf.int
```

The null hypothesis value of 26 falls in the confidence interval and has a p value much greater than 0.05. Thus, the null hypothesis is plausible.   

Here is a plot of the confidence interval and the boxplot of x1:

```{r}
# Plot the boxplot and ci
ci = val$conf.int
boxplot(x1, main="Sample x1")
abline(h=c(ci,mean(x1)),col=c("Red","Red","Green"))
```


To calculate the p-value using the T-distribution, $t_{calc}$ can be found. For $H_0: \mu = 24$:

```{r}
tcalc = (mean(x1)-24)/(sd(x1)/sqrt(30))
tcalc
```

The following function, `mypvalue` can be used alongside the above calculation to calculate p-values:

```{r}
# Display P-value areas
mypvalue=function(t0,xmax=4,n=20, alpha=0.05){
  #calculate alpha/2
  va=round(pt(-t0,df=n-1),4)
  pv=2*va
  
  # plot the t dist
  curve(dt(x,df=n-1),xlim=c(-xmax,xmax),ylab="T Density",xlab=expression(t),
  main=substitute(paste("P-value=", pv, " alpha=", alpha)))
  
  
  # set up points on the polygon to the right
  xcurve=seq(t0,xmax,length=1000)
  ycurve=dt(xcurve,df=n-1)
  
  # set up points to the left
  xlcurve=seq(-t0,-xmax,length=1000)
  ylcurve=dt(xcurve,df=n-1)
  
  # Shade in the polygon defined by the line segments
  polygon(c(t0,xcurve,xmax),c(0,ycurve,0),col="green")
  polygon(c(-t0,xlcurve,-xmax),c(0,ylcurve,0),col="green")
  
  # make quantiles
  q=qt(1-alpha/2,n-1)
  abline( v=c(q,-q),lwd=2) # plot the cut off t value 
  axis(3,c(q,-q),c(expression(abs(t[alpha/2])),expression(-abs(t[alpha/2]))))
  
  
  # Annotation
  text(0.5*(t0+xmax),max(ycurve),substitute(paste(area, "=",va)))
  text(-0.5*(t0+xmax),max(ycurve),expression(area))
  
  return(list(q=q,pvalue=pv))
}
```

Here is an example of the function in action:

```{r}
mypvalue(tcalc, n=30, alpha=0.05)
```

The rejection region for this plot is where the $t_{\frac{\alpha}{2}}$ lines are. This is around $t = \pm 2$. $t_{calc}$ is not in the rejection region. The p-value needed to reject the null hypothesis is 0.05, as found from $\alpha$.   

Bootstrapping can be used to find p-values as well. Below, the p-values are calculated using the `bootpval` function:

```{r}
bootpval<-function(x,conf.level=0.95,iter=3000,mu0=0, test="two"){
n=length(x)
y=x-mean(x)+mu0  # transform the data so that it is centered at the NULL
rs.mat<-c()    #rs.mat will become a resample matrix -- now it is an empty vector
xrs.mat<-c()
for(i in 1:iter){ # for loop - the loop will go around iter times
rs.mat<-cbind(rs.mat,sample(y,n,replace=TRUE)) #sampling from y cbind -- column bind -- binds the vectors together by columns
xrs.mat<-cbind(xrs.mat,sample(x,n,replace=TRUE)) #sampling from x cbind -- column bind -- binds the vectors together by columns

}

tstat<-function(z){ # The value of t when the NULL is assumed true (xbar-muo)/z/sqrt(n)
sqrt(n)*(mean(z)-mu0)/sd(z)
}

tcalc=tstat(x) # t for the data collected
ytstat=apply(rs.mat,2,tstat) # tstat of resampled y's, ytstat is a vector and will have iter values in it
xstat=apply(xrs.mat,2,mean)  # mean of resampled x's
alpha=1-conf.level # calculating alpha
ci=quantile(xstat,c(alpha/2,1-alpha/2))# Nice way to form a confidence interval
pvalue=ifelse(test=="two",length(ytstat[ytstat>abs(tcalc) | ytstat < -abs(tcalc)])/iter,
ifelse(test=="upper",length(ytstat[ytstat>tcalc])/iter,
length(ytstat[ytstat<xstat])/iter))

h=hist(ytstat,plot=FALSE)
mid=h$mid
if(test=="two"){
ncoll=length(mid[mid<= -abs(tcalc)])
ncolr=length(mid[mid>=  abs(tcalc)])
col=c(rep("Green",ncoll),rep("Gray",length(mid)-ncoll-ncolr),rep("Green",ncolr))
}
if(test=="upper"){
ncolr=length(mid[mid>=  abs(tcalc)])
col=c(rep("Gray",length(mid)-ncolr),rep("Green",ncolr))
}

if(test=="lower"){
ncoll=length(mid[mid<=  -abs(tcalc)])
col=c(rep("Green",ncoll),rep("Gray",length(mid)-ncoll))
}
hist(ytstat,col=col,freq=FALSE,las=1,main="",xlab=expression(T[stat]))
#segments(ci[1],0,ci[2],0,lwd=2)
pround=round(pvalue,4)
title(substitute(paste(P[value],"=",pround)))
return(list(pvalue=pvalue,tcalc=tcalc,n=n,x=x,test=test,ci=ci))
}
```

Here is the function in action for the same null hypothesis scenarios as above.  

- 22
```{r}
boot=bootpval(x=x1,mu0=22,test="two")
```

- 23
```{r}
boot=bootpval(x=x1,mu0=23,test="two")
```

- 24
```{r}
boot=bootpval(x=x1,mu0=24,test="two")
```

- 25
```{r}
boot=bootpval(x=x1,mu0=25,test="two")
```

- 26
```{r}
boot=bootpval(x=x1,mu0=26,test="two")
```

In general, these bootstrapped p-values are very close to the p-values determined by the t-tests performed earlier. As a result, I conclude that bootstrapping to find p-values is just as effective as using a t test.


# Task 3

Two samples are defined below:

```{r}
set.seed(30);
x=rnorm(15,mean=10,sd=7)

set.seed(40);
y=rnorm(20,mean=12,sd=4)
```

To test if the variances are equal, `var.test()` will be used.

```{r}
var.test(x, y)
```

We can conclude from this test that the variances are not equal, and in fact likely have a ratio near 3. The p-value is below 0.05, so we can reject the null hypothesis that the variances are equal, and proceed with the t-test under the assumption they are not equal. Therefore, during the following `t.test()` commands, the `var.equal` flag will be set to `FALSE`:

- $H_0: \mu_y - \mu_x = 0$
```{r}
t.test(x, y, mu = 0, var.equal = FALSE)
```
In this case, the null hypothesis would be accepted

- $H_0: \mu_y - \mu_x \ne 0$
```{r}
t.test(x, y, mu = 0, var.equal = FALSE)
```
By re-framing the test and flipping the roles of the alternate and the null, we can see that the null should be accepted. In this case, the small p-value is subtracted from 1 to be much greater than 0.05, so the null hypothesis is accepted.

- $H_0: \mu_y - \mu_x = 2$
```{r}
t.test(x, y, mu = 2, var.equal = FALSE)
```
In this case, the p-value is less than 0.05, so the null hypothesis is rejected.

- $H_0: \mu_y - \mu_x \ne 2$
```{r}
t.test(x, y, mu = 2, var.equal = FALSE)
```

In this test, if we switch the alternate and the null, we can see that the null hypothesis is accepted, because the p-value is actually $1 - p = 1 - 0.005881 > 0.05$.   

I have learned that the null hypothesis can trade places with the alternate during a t-test, depending on the framing of the problem. Additionally, the null hypothesis can be used in a variance test to determine if a future t-test needs to be run with equal variance or unequal variance assumptions.


# Task 4

Two samples with equal variance are made below
```{r}
set.seed(30);
x=rnorm(15,mean=10,sd=4)

set.seed(40);
y=rnorm(20,mean=12,sd=4)
```


The variance test is performed to see the ratio of the variances:
```{r}
var.test(x, y)
```

The null hypothesis of this test is that the variances are equal; since the resulting p-value is well above 0.05, we can accept the null and assume the variances are equal. In a t test, I would set `var.equal=TRUE`.

- $H_0: \mu_y - \mu_x = 0$
```{r}
t.test(x, y, mu = 0, var.equal = TRUE)
```
In this case, the null hypothesis would be rejected, however it is worth considering how close to 0.05 the p-value is.

- $H_0: \mu_y - \mu_x \ne 0$
```{r}
t.test(x, y, mu = 0, var.equal = TRUE)
```
By flipping the role of the alternate and the null, the null should be accepted. The formula of $1 - p$ yields a result much larger than 0.05 and should be accepted.

- $H_0: \mu_y - \mu_x = 2$
```{r}
t.test(x, y, mu = 2, var.equal = TRUE)
```

Likewise, the null would be rejected here as the p-value is much too low to regard the null as plausible.


- $H_0: \mu_y - \mu_x \ne 2$
```{r}
t.test(x, y, mu = 2, var.equal = TRUE)
```

Similar to above, the null should be accepted by pretending it is the alternate in this test. The alternate would normally be accepted in a case of equality, so the null is accepted as plausible.   

In general, to run a test where the null hypothesis is not immediately calculated, pretending the alternate hypothesis is the null works just fine. The key is to see if the alternate would be accepted, and if so, accept the null because the roles have flipped.


# Task 5

`boot2pval`:

```{r}
## Bootstrap interval for a two sample test
boot2pval<-function(x1,x2,conf.level=0.95,iter=3000,mudiff=0, test="two"){
n1=length(x1)
n2=length(x2)
y1=x1-mean(x1)+mean(c(x1,x2))  # transform the data so that it is centered at the NULL
y2=x2-mean(x2)+mean(c(x1,x2))
y1rs.mat<-c()    #rs.mat will be come a resample matrix -- now it is an empty vector
x1rs.mat<-c()
y2rs.mat<-c()
x2rs.mat<-c()
for(i in 1:iter){ # for loop - the loop will go around iter times
y1rs.mat<-cbind(y1rs.mat,sample(y1,n1,replace=TRUE)) #sampling from y cbind -- column bind -- binds the vectors together by columns
y2rs.mat<-cbind(y2rs.mat,sample(y2,n2,replace=TRUE))

}
x1rs.mat<-y1rs.mat+mean(x1)-mean(c(x1,x2))
x2rs.mat<-y2rs.mat+mean(x2)-mean(c(x1,x2))

xbar1=mean(x1)
xbar2=mean(x2)
sx1sq=var(x1)
sx2sq=var(x2)

tcalc=(xbar1-xbar2-mudiff)/sqrt(sx1sq/n1+sx2sq/n2)

sy1sq=apply(y1rs.mat,2,var)
sy2sq=apply(y2rs.mat,2,var) 
y1bar=apply(y1rs.mat,2,mean)
y2bar=apply(y2rs.mat,2,mean)

tstat=(y1bar-y2bar-mudiff)/sqrt(sy1sq/n1+sy2sq/n2)


alpha=1-conf.level # calculating alpha
#ci=quantile(xstat,c(alpha/2,1-alpha/2))# Nice way to form a confidence interval
pvalue=ifelse(test=="two",length(tstat[tstat>abs(tcalc) | tstat < -abs(tcalc)])/iter,
ifelse(test=="upper",length(tstat[tstat>tcalc])/iter,
length(ytstat[tstat<tcalc])/iter))

h=hist(tstat,plot=FALSE)
mid=h$mid
if(test=="two"){
ncoll=length(mid[mid<= -abs(tcalc)])
ncolr=length(mid[mid>=  abs(tcalc)])
col=c(rep("Green",ncoll),rep("Gray",length(mid)-ncoll-ncolr),rep("Green",ncolr))
}
hist(tstat,col=col,freq=FALSE)
#segments(ci[1],0,ci[2],0,lwd=2)

return(list(pvalue=pvalue))
#return(list(pvalue=pvalue,tcalc=tcalc,n=n,x=x,test=test,ci=ci))
}
```

Running the function on task 3 situations:

```{r}
set.seed(30);
x=rnorm(15,mean=10,sd=7)

set.seed(40);
y=rnorm(20,mean=12,sd=4)

boot2pval(x1=x,x2=y, mudiff = 0)

boot2pval(x1=x,x2=y, mudiff = 2)
```

Similar to Task 3, this finds that it is plausible for the differences between the sample means to be 0 or 2.

# Task 6

Task 4 situation:
```{r}
set.seed(30);
x=rnorm(15,mean=10,sd=4)

set.seed(40);
y=rnorm(20,mean=12,sd=4)
```

Running the function to verify result of bootstrapping
```{r}
boot2pval(x1=x,x2=y, mudiff = 0)

boot2pval(x1=x,x2=y, mudiff = 2)
```

Similar to Task 4, bootstrapping finds that it is possible to reject the null hypothesis with regard to the difference in mean between the samples being 0 or 2.

# Task 7

