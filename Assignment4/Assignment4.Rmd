---
title: 'Assignment 4'
author: "Justin Kleiber"
date: '`r format(Sys.Date(),format="%A, %B %d, %Y")`'
output: 
  html_document:
    df_print: paged
    fig_caption: true
    highlights: pygments
    number_sections: no
    theme: spacelab
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE, fig.align='center'}
knitr::opts_chunk$set(echo = TRUE)
```

# Questions{10/10}

## Q1

Loading the NZBIRDS data:
```{r}
birds = read.csv("NZBIRDS.csv")
```

a) Sampling the dataset
```{r}
samples = birds[sample(nrow(birds), 35, replace = TRUE), ]
samples
```

b) Mean and standard deviation:
```{r}
mean(samples$Body.Mass)
sd(samples$Body.Mass)
```

95% confidence interval:
```{r}
t = qt(1-0.05/2, 34)
upper = mean(samples$Body.Mass) + t*sd(samples$Body.Mass)/sqrt(35)
lower = mean(samples$Body.Mass) - t*sd(samples$Body.Mass)/sqrt(35)
c(lower, upper)
```

c) based on this sample, 95% of similar samples will have a mean body mass inside this interval.  

d) The mean of the population is 9113, which is inside the confidence interval. This is likely because the samples are taken from the population's distribution and have similar properties.

e) Using the sample, let's find egg length mean and standard deviation:
```{r}
mean(samples$Egg.Length)
sd(samples$Egg.Length)
```

Now, the 95% confidence interval for mean egg length:
```{r}
t = qt(1-0.05/2, 34)
upper = mean(samples$Egg.Length) + t*sd(samples$Egg.Length)/sqrt(35)
lower = mean(samples$Egg.Length) - t*sd(samples$Egg.Length)/sqrt(35)
c(lower, upper)
```

The mean egg length of the population (61.06) is inside this interval. This is likely because 95% of samples will be inside this interval and samples derive the properties of the parent distribution.

f) Confidence interval for the flightless birds study:
```{r}
p1 = 21/38
p2 = 7/78
q1 = 1 - p1
q2 = 1 - p2
38 * p1
78 * p2
38 * q1
38 * q2
```

All of these checks are greater than 4, so the normal approximation is good enough to find the difference in proportions:

```{r}
alpha = 0.05
n1 = 38
n2 = 78
z = qnorm(1-alpha/2)
lower = (p1 - p2) - z*sqrt((p1*q1/n1) + (p2*q2/n2))
upper = (p1 - p2) + z*sqrt((p1*q1/n1) + (p2*q2/n2))
ci = c(lower, upper)
ci
```

g) The confidence interval above supports this, as both bounds in the interval are positive.


## Q2
a) Using an equation, we can find the confidence interval for mean shear stress:

```{r}
y1 = 1312
y2 = 1352
s1 = 422
s2 = 271
n1 = 100
n2 = 47

z = qnorm(1 - 0.1/2)
z

# Confidence interval
upper = (y1 - y2) + z*sqrt((s1^2/n1) + (s2^2)/n2)
lower = (y1 - y2) - z*sqrt((s1^2/n1) + (s2^2)/n2)
ci = c(lower, upper)
ci
```


b) For the ratio of variances, the following R code can create a confidence interval
```{r}
flower = qf(1-0.1/2, 99, 46)
fupper = qf(1-0.1/2, 46, 99)

upper = s1^2 * fupper / s2^2
lower = s2^2 * flower / s2^2

ci = c(lower, upper)
ci
```

Based on this interval, there is evidence that the variances differ. This is because the ratio being 1 is not in the interval.


## Q3

a)
$$
Z = \frac{Y - \mu}{\sigma} = \frac{Y - 0}{\sigma} = \frac{Y}{\sigma}\\
Z^2 = \frac{Y^2}{\sigma^2}\\
\sum{Z_i^{2}} \sim \chi^2\\
\frac{Y^2}{\sigma^2} \sim \chi^2
$$

b) 
$$
P(\chi^2_{1-\alpha/2} \leq \chi^2 \leq \chi^2_{\alpha/2}) = 1 - \alpha\\
P(\chi^2_{1-\alpha/2} \leq \frac{Y^2}{\sigma^2}  \leq \chi^2_{\alpha/2}) = 1 - \alpha\\
P(\frac{1}{\chi^2_{\alpha/2}} \leq \frac{\sigma^2}{Y^2}  \leq \frac{1}{\chi^2_{1-\alpha/2}}) = 1 - \alpha\\
P(\frac{Y^2}{\chi^2_{\alpha/2}} \leq \sigma^2 \leq \frac{Y^2}{\chi^2_{1-\alpha/2}}) = 1 - \alpha\\
$$

## Q4

```{r}
rough = read.csv("ROUGHPIPE.csv")
t.test(rough$ROUGH, mu = 2)
```

a) The null hypothesis is $H_0: \mu = 2$, and the alternative hypothesis is $H_a: \mu \ne 2$.  

b) The test statistic is -1.02, and the p-value is 0.322  

c) The rejection region is found below
```{r}
rar = qt(1-0.05/2, length(rough$ROUGH) - 1)
rar
```

Any test statistic with an absolute value greater than this will be in the rejection region.  

d) The conclusion for the test is that the null hypothesis is plausible, as the test statistic is in the acceptance region.  

e) The test statistic is in the acceptance region, and the confidence interval shows the null hypothesis is plausible. Likewise the p-value shows the null hypothesis is plausible. All three of these indicators agree about the test results

## Q5

```{r}
lake = read.csv("WISCLAKES.csv")
```

a)
```{r}
t.test(lake$DOC, conf.level = 0.9, mu = 15)
```

It is very likely that the sample is representative of the population. The null hypothesis can be considered plausible since the p-value is so high.

b) A test can be made to find the null hypothesis p value for $\mu = 14$.
```{r}
test = t.test(lake$DOC, conf.level = 0.9, mu = 14)
1 - test$p.value
```

The probability is shown above, as it is $1 - p$.

## Q6
Lets load in the samples and test them:

```{r}
trees = read.csv("ORCHARD.csv")
fog = trees[trees$CONDITION == "FOG",]
clear = trees[trees$CONDITION == "CLEAR",]
t.test(fog$RATIO, clear$RATIO, conf.level = 0.95)
```

Based on this t test, it seems like the means of the two ratios may be equal. The confidence interval shows that the difference in the ratios could be 0, while the p-value is near 0.05. Given the p-value is greater than 0.05, can be considered plausible, however, it is quite close to the threshold at which the null may be implausible.

## Q7
Reading in the gas turbine data:
```{r}
gas = read.csv("GASTURBINE.csv")
head(gas)
```

a) Conducting a variance test for the heat rate variances of two different turbines:
```{r}
trad = gas[gas$ENGINE == "Traditional", ]
aero = gas[gas$ENGINE == "Aeroderiv",]
var.test(trad$HEATRATE, aero$HEATRATE, conf.level = 0.95)
```

Given the p-value is much less than 0.05, and the confidence interval does not contain 1, we can reject the null hypothesis as implausible. Therefore, the ratio of the variances is not 1, and therefore the assumption the variances are equal is faulty. This means 8.39's assumption is not acceptable.

b)Conducting a variance test for the heat rate variances of two new different turbines:
```{r}
adv = gas[gas$ENGINE == "Advanced", ]
aero = gas[gas$ENGINE == "Aeroderiv",]
var.test(adv$HEATRATE, aero$HEATRATE, conf.level = 0.95)
```

Based on this test, it is highly unlikely the variances are equal. The null hypothesis that states the ratio of the variances is 1 is rejected due to a low p-value and the confidence interval being nowhere close to containing 1. Therefore, the assumption made by 8.39 that the variances are equal is faulty.

## Q8
Loading in the ants data:
```{r}
ants = read.csv("GOBIANTS.csv")
head(ants)
```

a)
$$
H_0: \frac{\sigma_1^2}{\sigma_2^2} = 1\\
H_a: \frac{\sigma_1^2}{\sigma_2^2} \ne 1\\
$$

b) Splitting into two samples and performing a variance test:
```{r}
dry = ants[ants$Region == "Dry Steppe", ]
gobi = ants[ants$Region == "Gobi Desert", ]
var.test(dry$AntSpecies, gobi$AntSpecies, conf.level = 0.95)
qf(1-0.05/2, length(dry)-1, length(gobi)-1)
qf(0.05/2, length(dry)-1, length(gobi)-1)
```

As shown, the test statistic, F, is 1.3684.  

c) The rejection region is for any $F < 0.1718285$ or $F > 5.819757$.

d) The p-value is 0.7264.

e) The assumption that the variances are equal is quite plausible given the p-value is well above 0.05 and the confidence interval contains the test statistic (and contains 1) for the ratio of the variances. Additionally, the F statistic is in the acceptance region

f) The only assumption of this test is that the samples come from normally distributed populations.

## Q9
Loading in the throughput data

```{r}
robot = read.csv("THRUPUT.csv")
head(robot)
```

To find a difference in the means of throughput rate in this man vs machine sample, we use the following hypotheses:

$$
H_0 = \mu_1 - \mu_2 = 0\\
H_a = \mu_1 - \mu_2 \ne 0
$$

```{r}
t.test(robot$HUMAN, robot$AUTO, var.equal = TRUE, paired = TRUE)
```

From the test, the p-value is 0.03396 and the test statistic is -2.629. The 95% confidence interval is (-61.850346, -3.274654). Therefore, it is implausible that the difference in the means is 0 as none of these things support the null hypothesis enough.

## Q10

The `myboot` function below has been modified to suit the requirements:
```{r}
myboot<-function(iter=10000,x,fun="mean",alpha=0.05,...){  #Notice where the ... is repeated in the code
n=length(x)   #sample size

# Find the sample test data using a t test
sam_test = t.test(x, conf.level = 1 - alpha)
sam_ci = sam_test$conf.int

y=sample(x,n*iter,replace=TRUE)
rs.mat=matrix(y,nr=n,nc=iter,byrow=TRUE)
xstat=apply(rs.mat,2,fun) # xstat is a vector and will have iter values in it 
ci=quantile(xstat,c(alpha/2,1-alpha/2))# Nice way to form a confidence interval
# A histogram follows
# The object para will contain the parameters used to make the histogram
para=hist(xstat,freq=FALSE,las=1,
main=paste("Histogram of Bootstrap sample statistics","\n","alpha=",alpha," iter=",iter,sep=""),
...)

#mat will be a matrix that contains the data, this is done so that I can use apply()
mat=matrix(x,nr=length(x),nc=1,byrow=TRUE)

#pte is the point estimate
#This uses whatever fun is
pte=apply(mat,2,fun)
abline(v=pte,lwd=3,col="Black")# Vertical line
segments(ci[1],0,ci[2],0,lwd=4)      #Make the segment for the ci
text(ci[1],0,paste("(",round(ci[1],2),sep=""),col="Red",cex=2)
text(ci[2],0,paste(round(ci[2],2),")",sep=""),col="Red",cex=2)

segments(ci[1],0,ci[2],0,lwd=4)      #Make the segment for the sample ci
text(sam_ci[1],0.1,paste("(",round(sam_ci[1],2),sep=""),col="Blue",cex=2)
text(sam_ci[2],0.1,paste(round(sam_ci[2],2),")",sep=""),col="Blue",cex=2)

# plot the point estimate 1/2 way up the density
text(pte,max(para$density)/2,round(pte,2),cex=2)

return(list(ci=ci,fun=fun,x=x,t=sam_test$statistic,cit=sam_ci))# Some output to use if necessary
}
```

To show it in action, let's take a sample and call the function:
```{r}
set.seed(35)
sam<-round(rnorm(30,mean=20,sd=3),3)
myboot(x=sam)
```


