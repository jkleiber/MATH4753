---
title: "MATH 4753 Project 2"
author: "Justin Kleiber"
date:  "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: show
    csl: biomed-central.csl
    df_print: paged
    fig_caption: yes
    fig_height: 6
    fig_width: 7
    number_sections: yes
    theme: journal
    toc: yes
    toc_float: yes
  word_document:
    toc: yes
    toc_depth: 4
  pdf_document:
    df_print: kable
    fig_caption: yes
    fig_height: 6
    fig_width: 7
    highlight: tango
    toc: yes
    toc_depth: 4
always_allow_html: yes
bibliography: project.bib
abstract: This project is all about applications of SLR to real data using R
---

<center>

![Justin Kleiber](justin.jpg "Justin Kleiber"){ width=20% }

</center>



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(leaflet)
library(dplyr)
```

# My Video

<!--
<video width="320" height="240" controls>
  <source src="usingvideoinrmd.mp4" type="video/mp4">
Your browser does not support the video tag.
</video> -->


# Introduction

When applying for jobs, applicants are often asked about their desired salary, or their salary history. This is a tactic called "anchoring", where a potential employer tries to pin the future salary negotiations with the applicant to a low value in order to pay the lowest possible price for future labor (@KAHNEMAN1992296). Research studies have shown that such an approach influences negotiations, even if the anchor point is extreme (@thorsteinson).

Asking about salary history in particular has negative outcomes for women, leading some <a href = "https://www.nytimes.com/2018/05/01/upshot/how-a-common-interview-question-fuels-the-gender-pay-gap-and-how-to-stop-it.html">cities, states and companies to outlaw the question entirely </a> during the interview stages. Furthermore, it has been shown that women, who generally participate less in salary negotiations than their male counterparts, become more likely to negotiate their salary when armed with information about what they deserve to earn (@douglas2015availability).   

By applying simple linear regression to a given salary data set, it is predicted that such a model can accurately predict salary based on the amount of work experience an employee has. This model then can be used by the employee to achieve a more favorable outcome during salary negotiations, as a reasonable salary estimate can be predicted.  


## Variables

The two variables of interest are years of experience, and the salary earned. Both of these variables are quantitative. Salary is measured in US Dollars and the experience is measured in years to one decimal place.

```{r salarydata}
salary = read.csv("Salary_Data.csv")

library(DT)
datatable(
  salary,filter = 'top', options = list(
  pageLength = 5, autoWidth = TRUE, editable = TRUE, dom = 'Bfrtip',
    buttons = c('copy', 'csv', 'excel', 'pdf', 'print')),
caption = htmltools::tags$caption(
    style = 'caption-side: bottom; text-align: center;',
    'Table 2: ', htmltools::em('This is a simple caption for the table.')
  )
) %>%
  formatStyle('Salary',  color = 'red', backgroundColor = 'orange', fontWeight = 'bold')


```


### Plot

```{r carcharacteristics, fig.height = 5, fig.cap = "salary",fig.align='center',fig.cap="Graph of data with loess smoother"}
library(ggplot2)
g = ggplot(salary, aes(x = YearsExperience, y = Salary)) + geom_point()
g = g + geom_smooth(method = "loess")
g
```


## Data Collection

The salary data was sourced from <a href="http://kaggle.com">Kaggle</a>, a data science website with many interesting data sets.

## Reason For Collection

This data was originally collected to compare the salaries of many professionals, each at different career stages.

## Interest

This data provides an opportunity to study the efficacy of simple linear regression in predicting a worker's salary before the worker goes into salary negotiations.

## Problem

Employers frequently attempt to exploit employees by anchoring salary negotiations to an employee's past rather than considering the employee's current career stage. 

## Hypothesis

Simple linear regression can be used to provide job applicants and current employees with accurate salary information, with which they can use to better negotiate their own salary.

# Theory needed to carry out SLR

A linear combination is a weighted composition of potentially many variables, as shown below. 

$$
y = \beta_0 + \beta_1x_1 + ...+\beta_nx^n = \sum_{i=0}^n{\beta_ix^i}
$$

From @ch14, and the equation for a linear combination, it is determined that the output, $y_i$, of a linear model given a single input variable, $x_i$, is as follows:

$$
y_i = \beta_0 + \beta_1x_i + \epsilon_i
$$

Where $\epsilon_i$ represents the error of the model. This equation is known as the regression line. This equation can be used to find the expected value of $y_i$ given the input variable $x_i$. More formally:

$$
\begin{eqnarray}
E(y_i | x_i) &=& E(\beta_0 + \beta_1x_i + \epsilon_i)\\
E(y_i | x_i) &=& E(\beta_0) + E(\beta_1x_i) + E(\epsilon_i)\\
E(y_i | x_i) &=& \beta_0 + \beta_1x_i\\
\end{eqnarray}
$$

which aligns with the equation for a linear combination. However, this derivation relies on the assumption that $\epsilon_i ~ N(0, \sigma^2)$. In other words, the error of the model must be normally distributed with a mean of zero in order to be perfect. As most models are not perfect, they must be validated to see how well they fit the given data.


# Validity of Model

A linear model of the salary data is constructed using the following R code
```{r}
salary.lm = lm(Salary~YearsExperience, data = salary)
```

This model will undergo a variety of methods to confirm its validity in delivering a prediction about salary data.

## Straight trendline verification  

One assumption of simple linear regression with one input variable is that the model should be a straight line. This assumption is verified using `trendscatter`

```{r}
# Load the s20x library and make three trendline scatter plots
library(s20x)
layout(matrix(1:3, nrow = 3, ncol = 1))
trendscatter(Salary~YearsExperience, f = 0.5, data = salary)
trendscatter(Salary~YearsExperience, f = 0.7, data = salary)
trendscatter(Salary~YearsExperience, f = 0.9, data = salary)
```

From the `trendscatter` function calls above and the plots they output, the assumption that the trendline is straight is reasonable.

## Normally Distributed Errors 

For the model to work, the errors in the model need to be distributed normal, as shown below.

$$\epsilon_i \sim N(0,\sigma^2)$$

This section will seek to prove the normal distribution of the error using the Shapiro-Wilk test.

### Shapiro-Wilk Test

To perform the shapiro-wilk test on the errors, the `normcheck` function in R is employed:

```{r}
# Test the normality of the linear model
normcheck(salary.lm, shapiro.wilk = TRUE)
```

As the null-hypothesis of this particular Shapiro-Wilk test is that the error is normally distributed, and the p-value returned by the `normcheck` function is much greater than 0.05, it is reasonable to accept the null hypothesis as plausible. Therefore, the error being normally distributed is plausible.

## Constant Variance Verification

To show the constant variance of the error, the residuals must be plotted against the fitted values generated by the model. First the residuals and the fitted values are found using R:
```{r}
# Residuals
salary.res = residuals(salary.lm)

# Fitted values
salary.fit = fitted(salary.lm)
```

Then, the fitted values of the model and the residuals are plotted against each other

```{r}
# Plot residuals vs fitted values
plot(salary.fit, salary.res)
trendscatter(salary.fit, salary.res, f = 0.9)
```

This shows that the variance of the error is near constant, which will make the model much more accurate.

## Zero mean value of $\epsilon$

The mean value of the errors must be zero for the model to be valid. The mean of the errors can be found by first finding the residuals, and then finding the mean of the residuals.

```{r}
salary.res = residuals(salary.lm)
mean(salary.res)
```

As shown, the mean of the residuals is very close to 0. In fact, if floating point precision error in computers is considered, this value is zero.

## Data Independence

To show independence of the data, the residuals are plotted against the fitted values to show the lack of relationship

```{r}
plot(salary.lm, which = 1)
```

The above plot shows that the model misses some parts of the trend in the overall data. Despite this, the model will still likely be usable and effective.  


# Model Selection 

Another way to predict a salary is to add another coefficient to the equation. By adding another term, we can compare this model to the initial model
```{r}
salary.quad = lm(Salary~YearsExperience + I(YearsExperience^2), data = salary)
```

Comparing the summary for both linear models can be done using the `summary` function in R, as shown below for each model.

## Model 1
```{r}
summary(salary.lm)
```

$$R_{adj}^2 = 0.9554$$

## Model 2
```{r}
summary(salary.quad)
```

$$R_{adj}^2 = 0.9538$$

## Model Choice

Based on the above information, the first model with fewer terms has a better $R_{adj}^2$. This is because this model is more simple (it has fewer terms) and the second model fails to achieve significant improvement over the less complex model.





# Analysis

The plot of the trendline generated by the linear model is shown below:

```{r}
library(ggplot2)
g = ggplot(salary, aes(x = YearsExperience, y = Salary)) + geom_point(shape = 21, fill = "yellow")
g = g + with(salary.lm, geom_abline(intercept = coefficients[1], slope = coefficients[2], color = "Green", lwd = 1.25))
g
```

The model plots are also generated below for reference
```{r}
layout(matrix(1:4, nrow = 2, ncol = 2))
plot(salary.lm)
```


## Summary of the Model

The linear model generated using R is summarized below. The variables of interest are then analyzed to prove the model's effectiveness

```{r}
summary(salary.lm)
```


### Tests

In the summary of the model, notice that each parameter is tested against the null hypothesis that $\beta_i = 0$. Both of the parameters have p-values well below 0.05, which means this null hypothesis can be rejected. Additionally, the t-statistic is given. As shown below, the t-statistic for each parameter is inside the rejection region.

```{r}
qt(1-0.05/2, 28)
```

Since each t-statistic is bigger than this, the null hypothesis can be rejected.

### Multiple R squared
For this model, $R^2 = 0.957$, which shows that the data is correlated very well. An $R^2$ value close to 1 implies there is close to a one-to-one mapping between the independent variable and the dependent variable.

### Point estimates

This model suggests that the point estimate for a starting salary is \$25792.2, with a point estimate for the increase in salary per year as \$9450. These two point estimates are the parameters $\beta_0$ and $\beta_1$ respectively.

## $\beta$ Parameter Estimates

Beyond the initial point estimates, the data needs to be examined to determine the validity of the model parameters. This section outlines how the model parameters are effective for the given data.


### Model Adequacy

To determine how adequate this model is for the specific problem domain, the p-value is examined from the above summary for the linear model.  

For $\beta_0$, the p-value is 5.51e-12. The null hypothesis that $\beta_0 = 0$ is rejected as implausible, which means the model is adequate for this data.

### Prediction using the Model

In R, the `predict()` function can be used to estimate salary given years of experience. The `predict20x` function from the `s20x` package is also demonstrated

```{r}
predict(salary.lm, data.frame(YearsExperience=c(1,6,10)))
```

These predictions show the point estimates for an employee who has 1 year, 6 years, and 10 years of experience respectively. This can be helpful for an employee looking for the mean salary at their level of experience, but even more information can be gathered using confidence intervals:

```{r}
library(s20x)
predict20x(salary.lm, data.frame(YearsExperience=c(1,6,10)))
```

The same point estimates are calculated, but now with two different confidence intervals shown. One is a confidence interval based on the data, and the other is a confidence interval of the prediction. The first confidence interval gives an employee the range of salaries that may be represented in a sample of similarly experienced individuals. The second gives a range of what the prediction could be if given other data samples as input.  

For the employee, this data is very useful as they look to negotiate their salary.


### Confidence Intervals of $\beta$ Parameter Estimates

Using the `ciReg` function in R, we can calculate the confidence interval for $\beta_0$ and $\beta_1$ as shown below.
```{r}
ciReg(salary.lm)
```

The above function shows the 95% confidence interval for the parameter estimates, given the current data set.

### Outlier Detection

Using the cooks distance plotting function available in the `s20x` package, we can determine if certain data points are outliers. If outliers are found, they should be removed and the analysis shall be re-run to show the improvement of the model.

```{r}
cooks20x(salary.lm)
```

Data point #2 and #24 are the strongest data points in the set. By removing these data points, the model may improve. The analysis with the removed points is shown below:

```{r}
salary = salary[-c(2, 24),]
rmoutliers.lm = lm(Salary~YearsExperience, data=salary)
summary(rmoutliers.lm)
```

The model improved due to the removal of these powerful points, as shown by the higher $R^2$ and higher $R_{adj}^2$. The new trendline is shown below:

```{r}
library(ggplot2)
g = ggplot(salary, aes(x = YearsExperience, y = Salary)) + geom_point(shape = 21, fill = "pink")
g = g + with(rmoutliers.lm, geom_abline(intercept = coefficients[1], slope = coefficients[2], color = "Purple", lwd = 1.25))
g
```

Ultimately, the gain in performance is likely not enough to justify the points as outliers. Therefore, the initial model is sufficient for predicting salary data.


# Conclusion

Overall, the model was very effective at predicting salaries when given an employee's years of experience, as shown by the high correlation between these two variables. Undoubtedly, this model will work well to predict salary for a similar set of employees, and should be very helpful.    

To make this model even more useful, more data needs to be collected, and more industries need to be analyzed. Different industries will have different trends based on years of experience in that particular industry. Additionally, other factors should be considered, such as education levels or geography. Currently, this model is unable to capture these phenomena - that may need to be left to a more complicated multiple regression model.


# References
  
