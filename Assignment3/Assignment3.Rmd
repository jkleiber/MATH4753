---
title: 'Assignment 3'
author: "Justin Kleiber"
date: '`r format(Sys.Date(),format="%A, %B %d, %Y")`'
output: 
  html_document:
    df_print: paged
    fig_caption: true
    highlights: pygments
    number_sections: no
    theme: spacelab
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE, fig.align='center'}
knitr::opts_chunk$set(echo = TRUE)
```

# Questions{16/16}

## Q1
a) We must find the number of interarrival times of at least 120 seconds and divide by the total number of times, as shown below:
```{r}
phish = read.csv("PHISHING.csv")
length(phish[phish$INTTIME >= 120, ]) / length(phish$INTTIME)
```

b) An exponential distribution with $\beta = 95$ is $f(y) = \frac{e^{-y/95}}{95}$, with $\mu = 95$ and $\sigma^2 = 95^2 = 9025$.

The mean and variance of the phishing data is:
```{r}
mean(phish$INTTIME)
var(phish$INTTIME)
```

Since the mean is very close to the mean of an exponential distribution, and the variance is similar, the data follows an exponential distribution.


## Q2
a) For a gamma random variable, $\mu = \alpha\beta$ and $\sigma^2 = \alpha\beta^2$. Thus, for this distribution: $\mu = 3(0.07) = 0.21$ and $\sigma^2 = 3(0.07)^2 = 0.0147$

b) The chance of seeing this level can be analyzed using `dgamma` in R:
```{r}
dgamma(0.6, 3, 0.07)
```

Given that the probability is very low, it is unlikely that this level would be observed by a gamma distribution with these parameters. The maximum value of this distribution before a data point is an outlier is $\mu + 3\sigma$, which is $0.21 + 3*\sqrt{0.0147} = 0.5737$. This is the highest value that is in this distribution, indicating the maximum and that the 0.6 value is an outlier.

## Q3
a-b) For a gamma random variable, $\mu = \alpha\beta$ and $\sigma^2 = \alpha\beta^2$. Thus, for formula A: $\mu = 2(2) = 4$ and $\sigma^2 = 2(2)^2 = 8$, and for formula B: $\mu = 1(4) = 4$ and $\sigma^2 = 1(4)^2 = 16$.

c) `pgamma` can be used to find the probability that a gamma distribution acts in under a certain time (for the tear gas situation). For formula A:
```{r}
pgamma(1, 2, 2)
```

and for formula B:
```{r}
pgamma(1, 1, 4)
```

therefore, formula B has a higher probability of generating a reaction in under 1 minute.

## Q4
a) The probability of repair within the first two years can be found using `pweibull`:
```{r}
pweibull(2, 2, 4)
```

b) The mean of a weibull distribution is $\mu = \beta^\frac{1}{\alpha}\Gamma(\frac{\alpha + 1}{\alpha})$ and the variance is $\sigma^2 = \beta^\frac{2}{\alpha}[\Gamma(\frac{\alpha + 2}{\alpha}) - \Gamma^2(\frac{\alpha + 1}{\alpha})]$. Thus $\mu = \sqrt{4}*\Gamma(1.5) = 1.7725$ and $\sigma^2 = 4[\Gamma(2) - \Gamma^2(1.5)] = 0.8584$. Therefore $\sigma = 0.9265$.

The gamma function in R was used to obtain these gamma values:
```{r}
gamma(1.5)
gamma(2)
```


c) First, $\mu - 2\sigma = 1.7725 - 2(0.9265) = -0.0805$ and $\mu + 2\sigma = 1.7725 + 2(0.9265) = 3.6255$. In a Weibull distribution, the value cannot be below 0. To find this probability, we can simply use one `pweibull` function from R:
```{r}
pweibull(3.6255, 2, 4)
```

d) Since $\mu + 3\sigma = 1.7725 + 3(0.9265) = 4.552$, 6 years would be an outlier - thus it is not likely that a washing machine will last 6 years.


## Q5
a) Beta distributions have $\mu = \frac{\alpha}{\alpha + \beta}$ and $\sigma^2 = \frac{\alpha\beta}{(\alpha + \beta)^2(\alpha + \beta + 1)}$. So for the given parameters: $\mu = \frac{2}{2 + 9} = 0.1818$ and $\sigma^2 = \frac{2(9)}{(2+9)^2(2 + 9 + 1)} = \frac{18}{11^2(12)} = 0.0124$.

b) `pbeta` can be used to find the probability that 40% or more of the budget is used:
```{r}
1 - pbeta(0.4, 2, 9)
```

c) Yet again, `pbeta` is useful for finding if less than 10% of the budget will be used:
```{r}
pbeta(0.1, 2, 9)
```



## Q6
a) From the equations for a weibull distribution, the $\alpha$ and $\beta$ parameters are able to be found. By looking at the substitutions: $\alpha = 2$ and $\beta = 16$.

b) The mean of a weibull distribution is $\mu = \beta^\frac{1}{\alpha}\Gamma(\frac{\alpha + 1}{\alpha})$ and the variance is $\sigma^2 = \beta^\frac{2}{\alpha}[\Gamma(\frac{\alpha + 2}{\alpha}) - \Gamma^2(\frac{\alpha + 1}{\alpha})]$. Thus $\mu = \sqrt{16}*\Gamma(1.5) = 3.5449$ and $\sigma^2 = 16[\Gamma(2) - \Gamma^2(1.5)] = 3.4336$.

c) Using `pweibull` we can find the probability that a chip will not fail before 6 years:
```{r}
1 - pweibull(6, 2, 16)
```


## Q7
a) The joint probability distribution is $p(x,y) = \frac{1}{36}$ as all options are equally likely to occur

b) $p_1(x) = \Sigma_{y=1}^6 p(x,y) = 6(\frac{1}{36}) = \frac{1}{6}$ and $p_2(y) = \Sigma_{x=1}^6 p(x,y) = 6(\frac{1}{36}) = \frac{1}{6}$. Since all options are equally likely, this is true for all values of x and y in the respective marginal probability distributions.

c) $p_1(x | y) = \frac{p(x,y)}{p_2(y)} = \frac{\frac{1}{36}}{\frac{1}{6}} = \frac{1}{6}$. The same result holds for $p_2(y | x)$: $p_2(y | x) = \frac{p(x,y)}{p_1(x)} = \frac{\frac{1}{36}}{\frac{1}{6}} = \frac{1}{6}$.

d) The probability distributions from b and c are the same. This phenomenon is independence.


## Q8
a) The joint probability distribution takes the form of a table. The table represents the likelihood of each of the values occuring.

```{r}
mat = matrix(0, nrow = 3, ncol = 3)
mat[1, 1] = 1 / 7
mat[1, 2] = 2 / 7
mat[1, 3] = 1 / 7
mat[2, 3] = 2 / 7
mat[3, 3] = 1 / 7
tab = as.table(mat)
rownames(tab) <- 1:3
colnames(tab) <- 1:3
names(dimnames(tab)) <- c("y", "             x")
tab
```

b-c) The marginal distribution for each value can be found using the table by summing the probabilities for a particular row/column.

For x:
```{r}
x_mat = colSums(mat)
x_tab = as.table(x_mat)
names(x_tab) <- c("1", "2", "3")
x_tab
```

and for y:
```{r}
y_mat = rowSums(mat)
y_tab = as.table(y_mat)
names(y_tab) <- c("1", "2", "3")
y_tab
```

d) $p_2(y | x) = \frac{p(x,y)}{p_1(x)}$. So given each value of x and the tables above, we can find the conditional probability of y.

$p(y | 1)$:
```{r}
# p(1, y)
p1y = c(mat[1,1], mat[2,1], mat[3,1])
p2 = p1y / x_mat[1]
p2_tab = as.table(p2)
names(p2_tab) <- c("1", "2", "3")
p2_tab
```

$p(y | 2)$:
```{r}
# p(1, y)
p1y = c(mat[1,2], mat[2,2], mat[3,2])
p2 = p1y / x_mat[2]
p2_tab = as.table(p2)
names(p2_tab) <- c("1", "2", "3")
p2_tab
```

$p(y | 3)$:
```{r}
# p(1, y)
p1y = c(mat[1,3], mat[2,3], mat[3,3])
p2 = p1y / x_mat[3]
p2_tab = as.table(p2)
names(p2_tab) <- c("1", "2", "3")
p2_tab
```

## Q9
a)
$$
f(x,y) = \frac{e^{-y/10}}{10y}\\
f(y) = \int_y^{2y}{f(x,y)dx} = x\frac{e^{-y/10}}{10y}|_y^{2y}\\
f(y) = \frac{2e^{-y/10}}{10} - \frac{e^{-y/10}}{10} = \frac{1}{10}e^{-y/10}
$$

which is an exponential distribution.

b) Given this is an exponential distribution, the mean is $E(Y) = \beta = 10$.


## Q10
a. Finding c
$$
1 = \int_0^\infty{\int_0^x{ce^{-x^2}dydx}}\\
1 = c\int_0^\infty{xe^{-x^2}}dx\\
u = -x^2, \frac{du}{dx} = -2x, dx = -\frac{1}{2x}du\\
1 = -\frac{c}{2}\int_0^\infty{e^udu}\\
1 = -\frac{c}{2}[e^\infty - e^0]\\
1 = \frac{c}{2}\\
c = 2\\
$$

b) Marginal distribution
$$
f(x,y) = 2e^{-x^2}\\
f_1(x) = \int_{-\infty}^\infty{f(x,y)dy} = \int_{0}^x{2e^{-x^2}dy}\\
f_1(x) = 2e^{-x^2}\int_{0}^x{dy}\\
f_1(x) = 2xe^{-x^2}
$$
Given this, the marginal distribution sums to 1 over the open interval as shown below:
$$
1 = \int_{-\infty}^\infty{2xe^{-x^2}dx}\\
u = -x^2, du = -2xdx, dx = -\frac{1}{2x}du\\
1 = -\int_0^\infty{e^udu}\\
1 = -[e^\infty - e^0]\\
1=1
$$

c) Uniform conditional probability distribution
$$
f_2(y|x) = \frac{f(x,y)}{f_1(x)}\\
f_2(y|x) = \frac{2e^{-x^2}}{2xe^{-x^2}}\\
f_2(y|x) = \frac{1}{x}
$$

## Q11
R is used to prove this property

```{r}
# Joint probability distribution
jpd = matrix(c(1/12, 2/12, 1/12, 2/12,0,2/12,1/12,2/12,1/12), 3, 3, byrow=TRUE)
jpd

# Marginal distribution of X
p1x = matrix(colSums(jpd), nrow = 3, ncol=1)
p1x

# Marginal distribution of Y
p2y = rowSums(jpd)
p2y

# E(X)
Ex = sum(matrix(p1x * c(-1, 0, 1), ncol = 1, nrow=3))
Ex

# E(Y)
Ey = sum(p2y * c(-1, 0, 1))
Ey

# E(XY)
Exy = 0
for (x in -1:1)
{
  for(y in -1:1)
  {
    Exy = Exy + x*y*jpd[y+2, x+2]
  }
}
Exy

# Showing that E(XY) - E(X)E(Y) = 0
Exy - Ex*Ey

# Showing that X and Y are not independent
p1x%*%p2y
jpd
```


## Q12
a) The mean of a uniform sample is $\frac{a+b}{2}$, so $E(\bar{Y}) = \frac{1+3}{2} = 2$.

b) The variance of a uniform sample is $\frac{\sigma^2}{n}$ with $\sigma^2 = \frac{(b-a)^2}{12} = \frac{4}{12} = \frac{1}{3}$. So the variance of this sample is $\frac{\frac{1}{3}}{60} = \frac{1}{180} = 0.00556$.

c) By the central limit theorem, the shape of $\bar{Y}$ is a normal distribution.

d) `pnorm` can be used to find this value from the sample
```{r}
pnorm(2.5, mean = 2, sd = sqrt(1/180)) - pnorm(1.5, mean = 2, sd = sqrt(1/180))
```

e) Using `pnorm` again to find if uranium exceeds 2.2 ppm
```{r}
1 - pnorm(2.2, mean = 2, sd = sqrt(1/180))
```


## Q13
The mean of the sample distribution (normal) is equal to the mean of the binomial, $\mu = np = 20*0.4 = 8$. The variance is $\sigma^2 = npq = 20*0.4*0.6 = 4.8$

a) Normal approximation of a binomial for $P(Y \leq 1)$ using `pnorm`:
```{r}
pnorm(1.5, 8, sqrt(4.8))
```

b) Using `pnorm` to find $P(Y \geq 10)$ :
```{r}
1 - pnorm(10.5, 8, sqrt(4.8))
```


c) Using the table on page 998, for n=20, p=0.4: At k = 1, the probability is 0.0005. At k = 10, the probability is 0.8725. Subtracting the latter from 1 yields the answer to part B, 0.1275. This shows that the normal distribution is a close approximation of the binomial


## Q14
```{r}
leadcopp = read.csv("LEADCOPP.csv")
```

a) The interval can be found from the sample in R using `qt`
```{r}
lead_mean = mean(leadcopp$LEAD)
lead_sd = sd(leadcopp$LEAD)
n = length(leadcopp$LEAD)
alpha = 0.01
t = qt(1-alpha/2, n - 1)
mp = c(-1, 1)

ci = lead_mean + mp*t*lead_sd/sqrt(n)
ci
```

b) Similarly, we can find the interval for the copper mean:
```{r}
copp_mean = mean(leadcopp$COPPER)
copp_sd = sd(leadcopp$COPPER)
n = length(leadcopp$COPPER)
alpha = 0.01
t = qt(1-alpha/2, n - 1)
mp = c(-1, 1)

ci = copp_mean + mp*t*copp_sd/sqrt(n)
ci
```

c) For lead, there is a 99% probability that the population mean is less than 6.92 (lead levels cannot be negative). For copper, there is a 99% probability that the mean level is between 0.1519 and 0.6647.

d) 99% confidence means that 99% of sample means will fall inside the interval.


## Q15
```{r}
solar = read.csv("SOLARAD.csv")

# Difference between the solar irradiation levels
diff = solar$STJOS - solar$IOWA

# CI
alpha = 0.05
n = length(diff)
t = qt(1-alpha/2, n - 1)
mp = c(-1, 1)
ci = mean(diff) + mp*sd(diff)*t/sqrt(n)
ci
```

This means that 95% of the sample means for solar irradiation will fall inside this interval, based on this sample.


## Q16
a) The sample is analyzed to produce a 90% confidence interval below:
```{r}
diazinon = read.csv("DIAZINON.csv")
diff = diazinon$DAY - diazinon$NIGHT

# CI
alpha = 0.1
mp = c(-1, 1)
n = length(diff)
t = qt(1 - alpha/2, n - 1)
ci = mean(diff) + mp*t*sd(diff)/sqrt(n)
ci
```

b) We assume that the distribution of the differences is normal

c) The researchers should conclude that the day has far less average diazinon than the night. This is because the confidence interval shows that 90% of samples will be negative, indicating the day has lower levels across many samples.





